dataset:
  hf_name: "daniel3303/StoryReasoning"   # HuggingFace dataset name
  seq_len: 3                             # number of frames per example
  batch_size: 16
  image_size: 128                        # CNN encoder uses 128×128 images
  max_caption_len: 32
  max_reason_len: 32

model:
  image_feat_dim: 512                    # output of visual encoder CNN
  text_embed_dim: 300                    # LSTM embedding size
  text_hidden_dim: 512
  multimodal_dim: 512                    # projection dim after concatenation
  temporal_hidden_dim: 512               # LSTM over time dimension
  text_decoder_hidden: 512               # caption decoder LSTM size
  vocab_size: 30522                      # BERT-base-uncased tokenizer vocab
  pad_token_id: 0
  bos_token_id: 101
  eos_token_id: 102
  reason_embed_dim: 256      # <— NEW (else defaults to text_embed_dim)
  reason_hidden_dim: 512

training:
  lr: 1e-4
  epochs: 5
  device: "auto"
  grad_clip: 1.0
  log_interval: 50
  save_dir: "results/checkpoints"
